{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4be3946a",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/w4bo/handsOnDataPipelines/blob/main/materials/01-DataPreprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227b997a",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Integrated analytics lab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26347d32",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "Data analysis involves several steps:\n",
    "\n",
    "1. Frame the problem and look at the big picture\n",
    "   - Define the objective in business terms\n",
    "   - How should performance be measured?\n",
    "1. Get the data\n",
    "   - List the data you need and how much you need\n",
    "   - Collect of data from one or more sources (database, web, etc.)\n",
    "     - In this lab, things are much simpler\n",
    "1. Explore the data to gain insights\n",
    "   - Create an environment to keep track of your data exploration\n",
    "     - You have been provided with notebook environments\n",
    "   - Understanding of the structure and meaning of data\n",
    "1. Transformation of data into manageable formats for subsequent steps\n",
    "1. Extraction of knowledge from data (statistics, models, patterns, etc.)\n",
    "1. Validation of the extracted knowledge\n",
    "1. Deployment of the extracted knowledge and models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0600b8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![image](https://upload.wikimedia.org/wikipedia/commons/thumb/b/b9/CRISP-DM_Process_Diagram.png/1024px-CRISP-DM_Process_Diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae284be",
   "metadata": {
    "id": "4ae284be",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Relational data\n",
    "\n",
    "**Relational data** are usually collected in **tabular** format\n",
    "\n",
    "- Each row is an **observation** (instance or tuple)\n",
    "    - An object of the analysis\n",
    "    - E.g., a product for market basket analysis\n",
    "- Each column is an **attribute** (or feature) characterizing each object\n",
    "    - All values within a column have the same type (i.e., all values belong to the same attribute domain)\n",
    "    - E.g., the attributes ID (int), ProductName (str), or Price (float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85da03a2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Pandas** is the shorthand for 'Python and Data Analysis'\n",
    "\n",
    "- It provides a rich set of features for exploring and manipulating data\n",
    "- https://pandas.pydata.org/\n",
    "\n",
    "pandas (Python) is a solution for the manipulation of relational data\n",
    "\n",
    "- Two main data types: Series (e.g., temporal series) and DataFrame (e.g., table)\n",
    "- Support to SQL-like operations (join/merge, aggregation, etc.)\n",
    "- Imputation of missing values\n",
    "- Manipulation of data shape\n",
    "- By convention, the package pandas is imported as “pd”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aacb3166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff002373",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "... plus we will use other libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3932b785",
   "metadata": {
    "id": "3932b785",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np  # fast operations on arrays\n",
    "import seaborn as sns  # plots\n",
    "import matplotlib.pyplot as plt  # plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b277327a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Pandas relies on DataFrame and Series\n",
    "\n",
    "\n",
    "\n",
    "**DataFrame**:\n",
    "- Two-dimensional, size-mutable, potentially heterogeneous tabular data.\n",
    "- The primary pandas data structure.\n",
    "- Data structure also contains labeled axes (rows and columns).\n",
    "- Arithmetic operations align on both row and column labels.\n",
    "- Can be thought of as a dict-like container for Series objects.\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74c37032",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>f</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b  c  d  e  f   g   h   i   j\n",
       "0  0  1  2  3  4  5   6   7   8   9\n",
       "1  1  2  3  4  5  6   7   8   9  10\n",
       "2  2  3  4  5  6  7   8   9  10  11\n",
       "3  3  4  5  6  7  8   9  10  11  12\n",
       "4  4  5  6  7  8  9  10  11  12  13"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a numeric dataframe/table\n",
    "df = pd.DataFrame([[i + j for i in range(10)] for j in range(5)],\n",
    "                  index=[i for i in range(5)],\n",
    "                  columns=list('abcdefghij'))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0952b32b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A **Series** is a sequence of values with the same type\n",
    "\n",
    "- Each value is associate with a label\n",
    "- Supported values and label types are the ones from NumPy (float64, int64, etc.)\n",
    "- In other words, a series is a mono-dimensional vector of elements\n",
    "\n",
    "The index of a series is the sequence of labels\n",
    "\n",
    "- Label are usually numeric or string identifiers\n",
    "- E.g., the primary key of a database table\n",
    "- Labels could repeat within the series, but usually do not\n",
    "\n",
    "Technically\n",
    "\n",
    "- One-dimensional ndarray with axis labels (including time series).\n",
    "- Labels need not be unique but must be a hashable type (both integer- and label-based indexing).\n",
    "- Operations between Series (e.g., +, -, /) align values based on their associated index values.\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.Series.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "205a800c",
   "metadata": {
    "id": "205a800c",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    1\n",
       "b    2\n",
       "c    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series([1, 2, 3], index=[\"a\", \"b\", \"c\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4ed958f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    2\n",
       "3    3\n",
       "4    4\n",
       "Name: a, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select a column (i.e., a series) as in a SQL projection\n",
    "df['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "694287e9",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>f</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "      <th>k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b  c  d  e  f   g   h   i   j   k\n",
       "0  0  1  2  3  4  5   6   7   8   9   0\n",
       "1  1  2  3  4  5  6   7   8   9  10   2\n",
       "2  2  3  4  5  6  7   8   9  10  11   6\n",
       "3  3  4  5  6  7  8   9  10  11  12  12\n",
       "4  4  5  6  7  8  9  10  11  12  13  20"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add another column to the dataframe\n",
    "df['k'] = df['a'] * df['b']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbe3136",
   "metadata": {
    "id": "4fbe3136",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "... doing some element-wise operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a5bde6",
   "metadata": {
    "id": "50a5bde6"
   },
   "outputs": [],
   "source": [
    "ser_a = pd.Series([1, 2, 3], index=[\"a\", \"b\", \"c\"])\n",
    "ser_b = pd.Series([1, 2, 3], index=[\"b\", \"a\", \"c\"])\n",
    "ser_a + ser_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66690943",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_a - ser_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff604a1",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "ser_a * ser_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082224b9",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "ser_a / ser_b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfc9af7",
   "metadata": {
    "id": "2dfc9af7",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "... doing some aggregation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c64c8e",
   "metadata": {
    "id": "b2c64c8e"
   },
   "outputs": [],
   "source": [
    "ser_c = df[\"a\"]\n",
    "ser_c.count()  # => 5\n",
    "ser_c.sum()    # => 10\n",
    "ser_c.mean()   # => 2.0\n",
    "ser_c.max()    # => 4\n",
    "ser_c.min()    # => 0\n",
    "ser_c.idxmax() # => 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7860f33",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data preprocessing\n",
    "\n",
    "Data preprocessing plays a key role in a data analytics process and avoids “Garbage in, garbage out” [1]\n",
    "\n",
    "- A broad range of activities; from correcting errors to selecting the most relevant features\n",
    "- There are no pre-defined rules on the impact of pre-processing transformations\n",
    "- Data scientists cannot easily foresee the impact of pipeline prototypes\n",
    "\n",
    "“Garbage in, garbage out” is particularly applicable to data mining and machine learning\n",
    "- Out-of-range values (e.g., Income: −100)\n",
    "- Impossible data combinations (e.g., Exam mark: 15, Exam result: Passed) \n",
    "- Missing values\n",
    "- Inconsistent data among multiple sources\n",
    "- More?\n",
    "    \n",
    "[1] Joseph Giovanelli, Besim Bilalli, Alberto Abelló: Effective data pre-processing for AutoML. DOLAP 2021: 1-10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3602edb7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Which transformations can we apply?\n",
    "- **Encoding**: transforming categorical attributes into continuous ones\n",
    "- **Discretization**: transforming continuous attributes into categorical ones\n",
    "- **Normalization**: normalizing continuous attributes such that their values fall in the same range\n",
    "- **Imputation**: imputing missing values\n",
    "- **Rebalancing**: adjusting the class distribution of a dataset (i.e., the ratio between the different classes/categories represented)\n",
    "- **Feature Engineering**: defining the set of relevant attributes (variables, predictors) to be used in model construction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be16b6b0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Understanding data types\n",
    "\n",
    "\"It is imperative to know the attribute properties to carry out meaningful operations and research with them\"\n",
    "\n",
    "Why is data type important?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bac7b24",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![image](https://user-images.githubusercontent.com/18005592/232748093-a25e8ba7-24d4-4e2b-9e58-1553786cac33.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a378353",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A signed integer is a 32-bit datum that encodes an integer in the range:\n",
    "\n",
    "$[-2^{31}, 2^{31}-1] = [-2147483648, 2147483647]$\n",
    "\n",
    "$2201010001 > 2147483647$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d53489b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([\n",
    "    ['Cola',   'low',    '05/07/2021', 10],\n",
    "    ['Bread',  'medium', '05/07/2021', 25],\n",
    "    ['Beer',   'high',   '06/07/2021', 100],\n",
    "    ['Diaper', 'high',   '06/07/2021', np.nan],\n",
    "    ['Pizza',  'medium', '06/07/2021', 25]], columns=['ID', 'PriceBin', 'Date', 'Quantity'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cc984c",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The attribute type determines which operator can be applied to the attribute\n",
    "- Equality, sort, sum, ratio, etc.\n",
    "- It makes sense to compute the average `Quantity` but not the average `ID`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2ef244",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Different attribute types\n",
    "\n",
    "- (Categorical) **Nominal**: can distinguish the values (i.e., check equality)\n",
    "- (Categorical) **Ordinal**: can distinguish and sort the values\n",
    "- (Numeric) **Interval**: can distinguish and sort the values, and compute their difference\n",
    "- (Numeric) **Ratio**: can distinguish and sort the values, and compute their difference and ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5299b4b8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Pandas automatically infers data types, or they can be specified during creation\n",
    "- Common data types are numeric ones\n",
    "    - `np.floatN` represents floating numbers (e.g., -3.14)\n",
    "    - `np.intN`/`np.uintN` represent integers with/without sign (-42 and 42)\n",
    "    - `N` is the number of needed bits: 8, 16, 32 o 64\n",
    "- Other data types\n",
    "    - `bool`: Boolean values\n",
    "    - `datetime64`, timedelta64: timestamp and time intervals\n",
    "    - `object`: mainly used for strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41926ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3c26ed",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# data profiling\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4061127e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# To get some statistics (e.g., count, mean, std, min, etc.)\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cf8058",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Get the headers (i.e., the column names)\n",
    "df.columns\n",
    "\n",
    "# Get just the first two rows\n",
    "df.head(2)\n",
    "\n",
    "# Get just the last two rows\n",
    "df.tail(2)\n",
    "\n",
    "# Sort the dataframe by columns\n",
    "df.sort_values(by=['Quantity', 'ID'], ascending=[False, True])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3c0fec",
   "metadata": {
    "id": "6e3c0fec",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff9fa20",
   "metadata": {
    "id": "bff9fa20"
   },
   "outputs": [],
   "source": [
    "# array with distinct values sorted by first appearance\n",
    "df[\"Quantity\"].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3041345b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantity of unique values\n",
    "df[\"Quantity\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f596a69",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# return a new series that associates each value with its number of occurrences, sorted by frequency\n",
    "df[\"Quantity\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d99dac",
   "metadata": {
    "id": "a1d99dac"
   },
   "outputs": [],
   "source": [
    "df[\"Quantity\"].hist(bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a0329e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Which problems can cause skewed distributions?\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/18005592/232750742-aacbf6b3-8a7d-49c6-b253-5ab8e7985104.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0394c801",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Things are even more complex when applying sequences of transformations\n",
    "\n",
    "- E.g., normalization should be applied before rebalancing since rebalancing (e.g., by resampling) alters average and standard deviations\n",
    "- E.g., applying feature engineering before/after rebalancing produces different results which depends on the dataset and the algorithm\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/18005592/232754117-8a84fde5-bce2-41b1-a003-7dfa0b63f980.png)\n",
    "\n",
    "More an art than a science\n",
    "- ... At least for now\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f608753",
   "metadata": {
    "id": "5f608753",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Missing values\n",
    "\n",
    "Datasets often show missing values\n",
    "- E.g., they are not applicable (e.g., date of death) or unknown\n",
    "- A series can have missing values, referred to as `NA` (Not Available)\n",
    "- Numeric attributes: `NA` is `np.nan` (Not a Number)\n",
    "- `nan` is never equal, greater, or lower than other values (nor itself)\n",
    "\n",
    "        np.nan == np.nan\n",
    "        False\n",
    "- Numeric expressions with `nan` return `nan`\n",
    "\n",
    "        2 * np.nan – 1\n",
    "        nan\n",
    "Which problems arise from missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2f6e66",
   "metadata": {
    "id": "5c2f6e66",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# add the column \"isna\", True if the value is NaN\n",
    "df[\"isna\"] = df[\"Quantity\"].isna()\n",
    "# add the column \"notna\", False if the value is NaN\n",
    "df[\"notna\"] = df[\"Quantity\"].notna()\n",
    "df[[\"Quantity\", \"isna\", \"notna\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1dd6bd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Imputing missing values\n",
    "\n",
    "Several strategies\n",
    "\n",
    "- Replace `nan` with average or median values\n",
    "- Forward/backward fill\n",
    "- Dropping rows/columns with nans\n",
    "\n",
    "Which are the effects?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba624ad",
   "metadata": {
    "id": "fba624ad",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# fill the missing value with the average\n",
    "df[\"Quantity_imputed\"] = df[\"Quantity\"].fillna(df[\"Quantity\"].mean())  # fillna replaces NA values\n",
    "df[[\"Quantity\", \"Quantity_imputed\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d6b70f",
   "metadata": {
    "id": "06d6b70f",
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# fill the missing value with the previous (not NaN) value\n",
    "df[\"Quantity\"].fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8f5d63",
   "metadata": {
    "id": "0e8f5d63",
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# fill the missing value with the following (not NaN) value\n",
    "df[\"Quantity\"].fillna(method=\"bfill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aebd691",
   "metadata": {
    "id": "1aebd691",
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df[\"Quantity\"].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba31db2",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d876ba7",
   "metadata": {
    "id": "4d876ba7",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The `Housing` case study\n",
    "\n",
    "Check also: \n",
    "\n",
    "- https://www.kaggle.com/camnugent/california-housing-prices\n",
    "- https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/\n",
    "\n",
    "We will use the California Housing Prices dataset.\n",
    "Our task is to use California census data to forecast housing prices given the population, median income, and median housing price for each block group in California.\n",
    "Block groups are the smallest geographical unit for which the US Census Bureau publishes sample data (a block group typically has a population of 600 to 3,000 people).\n",
    "We will just call them \"districts\" for short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80970f2e",
   "metadata": {
    "id": "80970f2e",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"datasets/2022-bbs-dsaa-housing.csv\", delimiter=\",\")\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/w4bo/handsOnDataPipelines/main/materials/datasets/housing.csv\", delimiter=\",\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0584f0bf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "... and now?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c3d4a0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Answer some questions:\n",
    "\n",
    "- Which attributes (i.e., columns) are contained in the dataset?\n",
    "- Which is their semantics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9817e68c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb614d01",
   "metadata": {
    "id": "bb614d01",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Dataset description\n",
    "\n",
    "1. `longitude`: A measure of how far west a house is; a higher value is farther west\n",
    "2. `latitude`: A measure of how far north a house is; a higher value is farther north\n",
    "3. `housingMedianAge`: Median age of a house within a block; a lower number is a newer building\n",
    "4. `totalRooms`: Total number of rooms within a block\n",
    "5. `totalBedrooms`: Total number of bedrooms within a block\n",
    "6. `population`: Total number of people residing within a block\n",
    "7. `households`: Total number of households, a group of people residing within a home unit, for a block\n",
    "8. `medianIncome`: Median income for households within a block of houses (measured in tens of thousands of US Dollars)\n",
    "9. `medianHouseValue`: Median house value for households within a block (measured in US Dollars)\n",
    "10. `oceanProximity`: Location of the house w.r.t ocean/sea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85441c0b",
   "metadata": {
    "id": "85441c0b",
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# show some statistics on the dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a24b3a",
   "metadata": {
    "id": "e6a24b3a",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c117af",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "... are you satisfied with the understanding?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c042eb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "... what about data visualization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "H0bU-4jprHm3",
   "metadata": {
    "id": "H0bU-4jprHm3",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4, s=df[\"population\"]/100, label=\"population\", figsize=(10,7), c=\"median_house_value\", cmap=\"jet\", colorbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc8ca34",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What if we integrate open data?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd444066",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![image](https://user-images.githubusercontent.com/18005592/232756567-b706619a-2cc9-4b45-b78f-5172103e0c3b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048cadf1",
   "metadata": {
    "id": "048cadf1",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Memory usage\n",
    "\n",
    "What if I change float64 to float32?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1e7c90",
   "metadata": {
    "id": "8f1e7c90"
   },
   "outputs": [],
   "source": [
    "dff = df.copy(deep=True)  # copy the dataframe\n",
    "for x in df.columns:  # iterate over the columns\n",
    "    if dff[x].dtype == 'float64':  # if the column has type `float64`\n",
    "        dff[x] = dff[x].astype('float32')  # ... change it to `float32`\n",
    "dff.info()  # show some statistics on the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef54881",
   "metadata": {
    "id": "2ef54881",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Missing values\n",
    "There are some missing values for `total_bedrooms`. What should we do?\n",
    "\n",
    "Most Machine Learning algorithms cannot work with missing features. We have three options:\n",
    "- Get rid of the corresponding districts (i.e., drop the rows)\n",
    "    - `df.dropna(subset=[\"total_bedrooms\"])`\n",
    "- Get rid of the whole attribute (i.e., drop the columns)\n",
    "    - `df.drop(\"total_bedrooms\", axis=1`\n",
    "- Set the values to some value (zero, the mean, the median, etc.)\n",
    "    - `df[\"total_bedrooms\"].fillna(df[\"total_bedrooms\"].median())`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1d868f",
   "metadata": {
    "id": "ef1d868f",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Non-numeric attributes\n",
    "`ocean_proximity` is a text attribute so we cannot compute its median. Some options:\n",
    "- Get rid of the whole attribute. (`df.drop(\"ocean_proximity\", axis=1`)\n",
    "- Change from categorical to ordinal (e.g., `NEAR BAY` = 0, `INLAND` = 1)\n",
    "    - Can foresee any problem in this?\n",
    "    - ML algorithms will assume that two nearby values are more similar than two distant values. This may be fine in some cases (e.g., for ordered categories such as “bad”, “average”, “good”, “excellent”), but it is obviously not the case for the ocean_proximity column (for example, categories 0 and 4 are clearly more similar than categories 0 and 1). \n",
    "- Change from categorical to one hot encoding\n",
    "    - To fix this issue, a common solution is to create one binary attribute per category: one attribute equal to 1 when the category is “<1H OCEAN” (and 0 otherwise), another attribute equal to 1 when the category is “INLAND” (and 0 otherwise), and so on. This is called one-hot encoding, because only one attribute will be equal to 1 (hot), while the others will be 0 (cold). The new attributes are sometimes called dummy attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3297de8e",
   "metadata": {
    "id": "3297de8e",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df[\"ocean_proximity\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xkOk2VEdVkde",
   "metadata": {
    "id": "xkOk2VEdVkde",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df[\"ocean_proximity\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0ee037",
   "metadata": {
    "id": "8d0ee037",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Change from categorical to ordinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efd3a04",
   "metadata": {
    "id": "0efd3a04"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "y = ordinal_encoder.fit_transform(df[[\"ocean_proximity\"]])\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe14dd8c",
   "metadata": {
    "id": "fe14dd8c",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "From categorical to one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3db3bf4",
   "metadata": {
    "id": "d3db3bf4"
   },
   "outputs": [],
   "source": [
    "y = pd.get_dummies(df[\"ocean_proximity\"], prefix='ocean_proximity')\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4969d930",
   "metadata": {
    "id": "4969d930",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570f14ff",
   "metadata": {
    "id": "570f14ff",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "df.hist(bins=50, figsize=(20, 15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddb3f44",
   "metadata": {
    "id": "5ddb3f44",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Open questions:\n",
    "\n",
    "- `median_income` should be in dollars. However, it has a strange range. Why? \"you are told that the data has been scaled and capped at 15 (actually 15.0001) for higher median incomes, and at 0.5 (actually 0.4999) for lower median incomes. The numbers represent roughly tens of thousands of dollars. The numbers represent roughly tens of thousands of dollars\"\n",
    "- `housing_median_age` and `median_house_value` are capped. As to `median_house_value`, this is a serious problem since it is your target attribute (your labels). Your Machine Learning algorithms may learn that prices never go beyond that limit. You need to check with your client team (the team that will use your system’s output) to see if this is a problem or not. If they tell you that they need precise predictions even beyond 500,000USD, then you have mainly two options: (a) collect proper labels for the districts whose labels were capped, (b) remove those districts from the training set.\"\n",
    "- These attributes have very different scales. Should we scale them?\n",
    "- Many histograms are tail heavy: they extend much farther to the right of the median than to the left. This may make it a bit harder for some Machine Learning algorithms to detect patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cea513",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Are the relationships between variables?\n",
    "\n",
    "- A grid of Axes such that each numeric variable in data will by shared across the y-axes across a single row and the x-axes across a single column\n",
    "- The diagonal plots are treated differently: a univariate distribution plot is drawn to show the marginal distribution of the data in each column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jFvRyNbGV36l",
   "metadata": {
    "id": "jFvRyNbGV36l",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "tmp = df[[\"median_income\", \"housing_median_age\", \"median_house_value\", \"households\", \"population\", \"total_rooms\"]]\n",
    "sns.pairplot(tmp.sample(n=1000, random_state=42), hue='median_house_value', markers='+')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dZsHkY_yV5zN",
   "metadata": {
    "id": "dZsHkY_yV5zN",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Check correlations and intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FYZ7EdT2V8Le",
   "metadata": {
    "id": "FYZ7EdT2V8Le",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "rho = df.corr(method='pearson')\n",
    "pval = df.corr(method=lambda x, y: pearsonr(x, y)[1]) - np.eye(*rho.shape)\n",
    "p = pval.applymap(lambda x: ''.join(['*' for t in [0.01, 0.05, 0.1] if x <= t]))\n",
    "rho.round(2).astype(str) + p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EmnZ1P4uV9H1",
   "metadata": {
    "id": "EmnZ1P4uV9H1",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "min_corr = 0.3\n",
    "kot = rho[(abs(rho) >= min_corr) & (rho < 1)]\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(kot, cmap=sns.color_palette(\"coolwarm\", as_cmap=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69801a8d",
   "metadata": {
    "id": "69801a8d",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Scaling attributes\n",
    "\n",
    "Attributes have very different scales. Should we scale them?\n",
    "\n",
    "\n",
    "- Normalization is good to use when you know that the distribution of your data does not follow a Gaussian distribution. This can be useful in algorithms that do not assume any distribution of the data like K-Nearest Neighbors and Neural Networks.\n",
    "- Standardization, on the other hand, can be helpful in cases where the data follows a Gaussian distribution. However, this does not have to be necessarily true. Unlike normalization, standardization does not have a bounding range. So, even if you have outliers in your data, they will not be affected by standardization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e312e6b6",
   "metadata": {
    "id": "e312e6b6",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Min-max normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6974275",
   "metadata": {
    "id": "e6974275"
   },
   "outputs": [],
   "source": [
    "num_df = df.drop(columns=['ocean_proximity', 'median_house_value'])\n",
    "normalized_df = (num_df - num_df.min()) / (num_df.max() - num_df.min())\n",
    "normalized_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0195d8f8",
   "metadata": {
    "id": "0195d8f8",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39239dcf",
   "metadata": {
    "id": "39239dcf"
   },
   "outputs": [],
   "source": [
    "num_df = df.drop(columns=['ocean_proximity', 'median_house_value'])\n",
    "normalized_df = (num_df - num_df.mean()) / num_df.std()\n",
    "normalized_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d11b42",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This checklist can help you while building your projects\n",
    "- Frame the problem and look at the big picture\n",
    "   - ✔ Define the objective in business terms\n",
    "   - ✖ How should performance be measured?\n",
    "- Get the data\n",
    "   - ✔ List the data you need and how much you need\n",
    "- Explore the data to gain insights\n",
    "   - ✔ Create an environment to keep track of your data exploration \n",
    "   - ✔ Study each attribute and its characteristics\n",
    "- Prepare the data\n",
    "   - ✔ Fix or remove outliers (optional)\n",
    "   - ✔ Fill in missing values (e.g., with zero, mean, median…) or drop their rows (or columns)\n",
    "   - ✔ Feature selection (optional): drop the attributes that provide no useful information for the task\n",
    "   - ✔ Feature engineering, where appropriate: discretize continuous features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681562cb",
   "metadata": {
    "id": "681562cb",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Hands on!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4ed12b",
   "metadata": {
    "id": "ef4ed12b"
   },
   "outputs": [],
   "source": [
    "num_df = df.copy(deep=True).drop(columns=[\"ocean_proximity\"])  # do not change this line\n",
    "\n",
    "# Filling in (i.e., impute) missing values with the median value\n",
    "num_df[\"total_bedrooms\"] = 1  # change `1` with the proper solution\n",
    "\n",
    "# Add a new column: population_per_household = population / households\n",
    "num_df[\"population_per_household\"] = 1  # change `1` with the proper solution\n",
    "\n",
    "# Add a new column: rooms_per_household = total_rooms / households\n",
    "num_df[\"rooms_per_household\"] = 1  # change `1` with the proper solution\n",
    "\n",
    "# Add a new column: bedrooms_per_room = total_bedrooms / total_rooms\n",
    "num_df[\"bedrooms_per_room\"] = 1  # change `1` with the proper solution\n",
    "\n",
    "# Apply standardization to all the numeric columns\n",
    "num_df = pd.DataFrame()  # change `pd.DataFrame()` with the proper solution\n",
    "\n",
    "# One hot encode `ocean_proximity` since it is a categorical attribute\n",
    "# change `pd.DataFrame()` with the proper solution (hint: pd.get_dummies)\n",
    "cat_df = pd.DataFrame()\n",
    "\n",
    "clean_df = pd.concat([num_df, cat_df], axis=1)  # do not change this line\n",
    "clean_df"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
